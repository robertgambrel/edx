---
title: "Homework 6"
author: "Robert Gambrel"
date: "June 28, 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

if (Sys.info()[[1]] == "Windows" & Sys.info()['user'] == 'gambrel') {
  setwd("E:/GoogleDrive/edx/6501x/week6")
} else if (Sys.info()['user'] == "robert.gambrel") {
  setwd("C:/Users/robert.gambrel/Documents/edx")
} else if (Sys.info()[[1]] == "Linux") {
  setwd("~/Documents/edx/6501x/week6")
}

```

```{r} 

pacman::p_load(dplyr, tidyr, magrittr, readr, purrr, stats, outliers, 
               lubridate, ggplot2, glmnet, FrF2, tibble, broom, mice)
set.seed(42)
```

# Q1

I tried multiple configurations of the passenger check-in process to minimize resources. The first bottleneck was the ticketing gate checkin. If I included less than 4 agents here, the process had a mean throughput time of 19 minutes, even with maximum security gates allowed. I next iteratively reduced the security capacity - the image below shows the point at which security was insufficient to meet the demands of the assignment. I started with 6 security gates and removed them one at a time to find the minimum necessary to keep wait times low. Under the 3-queue system below, mean throughput time in this model was 22 minutes. Under the conditions we chose in the model, I therefore needed 4 ticketing agents and 4 security lines to consistently achieve a mean passenger wait time of 15 minutes or less.

![Arena Simulation Design](simulation_flow.png)
# Q2
```{r}
cancer <- read_csv('breast-cancer-wisconsin.data.txt', na = '?',
                   col_types = c('idddddddddi'),
                   col_names =  c('sample_id', 'clump_thickness', 'cell_size_uniformity',
                   'cell_shape_uniformity', 'marginal_adhesion', 'epithelial_cell_size',
                   'bare_nuclei', 'bland_chromatin', 'normal_nucleoli', 'mitoses', 'class'))

names(cancer) <- c('sample_id', 'clump_thickness', 'cell_size_uniformity',
                   'cell_shape_uniformity', 'marginal_adhesion', 'epithelial_cell_size',
                   'bare_nuclei', 'bland_chromatin', 'normal_nucleoli', 'mitoses', 'class')

cancer$malignant <- ifelse(cancer$class == 4, 1, 0)

cancer$class <- NULL

sum(complete.cases(cancer))
summary(cancer)

```

I first do mean imputation. Since each predictor column is continuous, I do not need to worry about modal imputation. Even though `bare_nuclei` is the only column with missing values, my function will check every column except the `sample_id` variable and the `malignant` outcome variable.

```{r}
# duplicate dataset, which will be updated with mean values where missing
mean_imputed <- cancer

na.assign <- function(col, val) {
  col[is.na(col)] <- val
  return(col)
}

for (var in names(mean_imputed)[2:10]) {
  # column mean of non-missing data
  mean_val = mean(mean_imputed[[var]], na.rm = T)
  
  # update if missing
  mean_imputed[, var] <- na.assign(mean_imputed[,var], mean_val)
  
}
sum(complete.cases(mean_imputed))
summary(mean_imputed)
```
There are no entries of `bare_nuclei` that are missing now. The mean stays the same, which we woul dexpect after mean imputation.

I next use the `mice` package to do regression imputation. First, I use the predicted value with no error.

```{r}
predicted_imputation <- mice(cancer, m = 1, method = 'norm.predict')
predicted_imputation_values <- complete(predicted_imputation)
summary(predicted_imputation_values)
sd(predicted_imputation_values$bare_nuclei)
```

Next, I allow for some prediction error around the imputed value, based on the model's standard error.

```{r}
predicted_imputation_w_err <- mice(cancer, m = 1, method = 'norm.nob')
predicted_imputation_w_err_values <- complete(predicted_imputation_w_err)
summary(predicted_imputation_w_err_values)
sd(predicted_imputation_w_err_values$bare_nuclei)

```
